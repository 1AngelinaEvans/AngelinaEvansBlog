[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About Angelina\n\nAngelina Evans is a senior at the University of Iowa. She is pursuing a major in Geography, as well as minors in Computer Science and Environmental Policy and Planning. Angelina is interested in how GIS and data science can be used to change or understand the world as we know it. In the Fall of 2023, she will begin the first year of the University of Iowa Undergraduate to Graduate (U2G) master’s degree program in Informatics with a focus in Geoinformatics. In the future, Angelina hopes to use her knowledge to identify problems and provide solutions to environmental and social issues related to climate change, disasters, pollution, health, and wellbeing."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AngelinaEvansBlog",
    "section": "",
    "text": "Week 3 Blog\n\n\n\n\n\n\n\nWeek Three\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2023\n\n\nAngelina Evans\n\n\n\n\n\n\n  \n\n\n\n\nTeam Blog for Week 3\n\n\n\n\n\n\n\nWeek 3\n\n\nWeekly Wrap-ups\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2023\n\n\nAngelina Evans\n\n\n\n\n\n\n  \n\n\n\n\nWeek 1 Blog\n\n\n\n\n\n\n\nWeek One\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nAngelina Evans\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2 Blog\n\n\n\n\n\n\n\nWeek Two\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nAngelina Evans\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Week1Blog/AngelinaWeek1.html",
    "href": "posts/Week1Blog/AngelinaWeek1.html",
    "title": "Week 1 Blog",
    "section": "",
    "text": "My First Week with DSPG\nDuring week one, I took a couple data camp courses to get more familiar with topics in R, Github, and web scraping in R.\nHere is an example of what I did in the Intro to R course. In the code below, there are two vectors: scores and comments. The scores represent the ratings of different movies and comments are opinions of viewers.\n\nscores <- c(4.6, 5, 4.8, 5, 4.2)\ncomments <- c(\"I would watch it again\", \"Amazing!\", \"I liked it\", \"One of the best movies\", \"Fascinating plot\")\n\nI can get the mean of the scores vector by writing:\n\nmean(scores)\n\n[1] 4.72\n\n\nSomething that was very new to me in R was matrices. I learned how to create them and how to reference specific rows and columns.\n\n# Vector with numerics from 1 up to 10\nmy_vector <- 1:10 \n\n# Matrix with numerics from 1 up to 9\nmy_matrix <- matrix(1:9, ncol = 3)\n\n# First 10 elements of the built-in data frame mtcars\nmy_df <- mtcars[1:10,]\n\n# Construct list with these different elements:\nmy_list <- list(my_vector,my_matrix,my_df)\n\nI plan to complete these courses: Intermediate R, Web Scraping in R, and AI Fundamentals.\n\n\n\nHere are two courses I want to complete soon. I also plan to take the AI Fundamentals course."
  },
  {
    "objectID": "posts/Week2Blog/AngelinaWeek2.html",
    "href": "posts/Week2Blog/AngelinaWeek2.html",
    "title": "Week 2 Blog",
    "section": "",
    "text": "TidyCensus\nKyle Walker’s tutorials introduce TidyCensus in R.\nHere is a bar graph showing median income for Story, Grundy, Chickasaw, and Buchanan counties. Also included is each estimate’s margin of error.\n\nlibrary(tidycensus)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nmedian_income <- get_acs(\n  geography = \"county\",\n  variables = \"B19013_001\",\n  year = 2021\n)\n\nGetting data from the 2017-2021 5-year ACS\n\nwinvest_counties <- get_acs(\n  geography = 'county',\n  state = 'IA',\n  county = c('Story', 'Grundy', 'Chickasaw', 'Buchanan'),\n  variables = \"B19013_001\",\n  year = 2021,\n  survey = 'acs5' \n)\n\nGetting data from the 2017-2021 5-year ACS\n\nggplot(winvest_counties, aes(y = estimate, x = NAME)) + \n  ggtitle(\"Median Income\")+\n  geom_bar(stat=\"identity\", color = \"#3182bd\", fill=\"#9ecae1\")+labs(x=\"county name\",y=\"dollars\")+\n  scale_x_discrete(labels = function(x) str_remove(x, \" County, Iowa|, Iowa\"))+\n  geom_errorbar(aes(ymin = estimate - moe, ymax = estimate + moe),\n              width = 0.5, linewidth = 0.5)\n\n\n\n\n\n\nGitHub and Blogs\nWe also had a GitHub workshop this week to get familiar with GitHub actions. I created my own folder and ReadMe in the DSPG2023 Repo. We also created blogs using quarto/ RStudio.\n\n\nThings to Work On\nSetting up everything, especially the blog posts took a while and I had trouble with getting my changes to show up on GitHub. Thankfully I was able to get help and eventually got everything to show up correctly. I am looking forward to improving my blog pages and trying new things."
  },
  {
    "objectID": "posts/Week3Blog/AngelinaWeek3.html",
    "href": "posts/Week3Blog/AngelinaWeek3.html",
    "title": "Week 3 Blog",
    "section": "",
    "text": "This week was all about getting a better idea of the project’s direction and learning about ways to accomplish our project goals.\n\n\nOne idea for the project is that we can web scrape from housing assessor websites such as Iowa Assessors and Trulia. If we are able to successfully do so, we can use images of houses and other information to train our AI model. I focused on learning more about web scraping using R through the DataCamp Course called Web Scraping in R. Before that I also worked on the Intermediate R course to better understand what can be done with R. I have been trying to understand the web scraping process using DataCamp and other online tutorials.\nWe are also trying to gather images of houses and other data using a google API.\n\n\n\nExample of what I have been learning in DataCamp.\n\n\n\n\n\n\nAssessor page for buchanan county\n\n\n\n\n\nSomething that has been interesting this week is learning how we can use AI to help with our project. I am learning more about AI through the videos: Getting Started with Python Deep Learning for Beginners and Build a Deep CNN Image Classifier with ANY Images, and Gavin’s explaining.\n\n\n\nOne of my hopes from week 2 was that I would get better with editing and updating blogs. Now I feel a bit more comfortable with the blogs and things are working better for me.\nI also think that my group has a good idea of what we should get done. We were also able to come up with steps (ex. creating trials for our AI model that would be easier to troubleshoot).\n\n\n\nI definitely want to make more progress with web scraping because that is a key part of the project."
  },
  {
    "objectID": "posts/Week3TeamBlog/Week3TeamBlog.html",
    "href": "posts/Week3TeamBlog/Week3TeamBlog.html",
    "title": "Team Blog for Week 3",
    "section": "",
    "text": "This week, our group was able to spend time thinking and talking about:\n- Our takeaways from last week’s client meeting\n- Project goals\n- Methods to use when working to reach project goals\n- New ideas to add into our project\n\n\n\nCurrent plan for our project.\n\n\n\n\nWe currently have ideas to scrape from housing assessor websites such as Iowa Assessors and Trulia. If we are able to successfully do so, images of houses and other information can be utilized to train our AI model(s).\nAngelina and Kailyn focused on learning more about web scraping using R through the DataCamp Course called Web Scraping in R. They also began to follow steps for scraping the web using other tutorials.\nWe also hope to gather images of houses and other data using a Google API.\n\n\n\nThis sample model was trained to determine if a house has vegetation or no vegetation. Here are the steps:"
  }
]